{"cells":[{"cell_type":"code","source":["%pip install Shapely\n","import json, pandas as pd\n","\n","with open(\"/lakehouse/default/Files/GIS Data/City Wards Data TopoJSON - 4326.json\") as f:\n","    topo = json.load(f)\n","\n","layer_name = list(topo[\"objects\"].keys())[0]\n","features = topo[\"objects\"][layer_name][\"geometries\"]\n","\n","# Arcs is the full set of coordinates with delta steps from an origin point \n","# The origin point is provided by the translate attribute below\n","# Transform provides translate, the origin point and scale, the multiplying factor \n","# Scale is used to multiply the delta values to convert to real-world coords\n","arcs = topo[\"arcs\"]\n","transform = topo[\"transform\"]\n","scale = transform[\"scale\"]\n","translate = transform[\"translate\"]\n","\n","# Decode arcs into coordinates\n","def decode_arc(arc):\n","    coords = []                # Final list to store decoded (lon, lat) coordinates\n","    x, y = 0, 0                # Start at origin (0, 0)\n","\n","    for dx, dy in arc:        # Example arc: [[1, 0], [1, 0], [0, 1]]\n","        x += dx               # Step 1: x = 0 + 1 → x = 1\n","        y += dy               # Step 1: y = 0 + 0 → y = 0\n","\n","        lon = x * scale[0] + translate[0]   # lon = 1 * 0.01 + (-79.5) → -79.49\n","        lat = y * scale[1] + translate[1]   # lat = 0 * 0.01 + 43.6 → 43.6\n","\n","        coords.append((lon, lat))          # First point: (-79.49, 43.6)\n","\n","    return coords             # Returns: [(-79.49, 43.6), (-79.48, 43.6), (-79.48, 43.61)]\n","\n","\n","# Resolve arc indices to arcs including handling reversed arcs\n","def resolve_arcs(arc_indices): #arc indices refer to the positions of the full list of arcs\n","    coords = []  # Final list to store all decoded coordinates for the shape\n","\n","    for idx in arc_indices:  # Example: arc_indices = [0, -1, 2]\n","        arc = arcs[abs(idx)]  # Get arc by absolute index\n","        # Step 1: idx = 0 → abs(0) = 0 → arc = arcs[0]\n","        # Step 2: idx = -1 → abs(-1) = 1 → arc = arcs[1]\n","        # Step 3: idx = 2 → abs(2) = 2 → arc = arcs[2]\n","\n","        if idx < 0:\n","            arc = arc[::-1]  # Reverse arc if index is negative using list slicing technique\n","            # Step 2: idx = -1 → reverse arcs[1] to walk it backward\n","\n","        coords.extend(decode_arc(arc))  # Decode arc into real-world coordinates and append\n","        # Each call to decode_arc returns a list of (lon, lat) tuples\n","        # These are added to the final coords list to build the full polygon\n","\n","    return coords  # Returns the full list of decoded coordinates for the shape\n","\n","\n","# Build WKT Polygons\n","from shapely.geometry import Polygon  # Import Polygon class to create geometric shapes\n","\n","rows = []  # Final list to store enriched property dictionaries. A list of dictionaries.\n","\n","for f in features:  # Loop through each feature in the TopoJSON layer\n","    props = f[\"properties\"]  # Extract metadata like WARD_ID, AREA_NAME, etc.\n","    # Example: props = {\"WARD_ID\": \"07\", \"AREA_NAME\": \"York South–Weston\"}\n","\n","    # Extract arc indices for the polygon\n","    arc_indices = f[\"arcs\"][0] if isinstance(f[\"arcs\"][0], list) else f[\"arcs\"]\n","    # Example: f[\"arcs\"] = [[0, -1, 2]] → arc_indices = [0, -1, 2]\n","    # If f[\"arcs\"] = [0, -1, 2] directly (no nesting), it still works\n","\n","    coords = resolve_arcs(arc_indices)  # Decode arc indices into real-world coordinates\n","    # Example output: [(-79.49, 43.6), (-79.48, 43.6), (-79.48, 43.61), ...]\n","\n","    polygon = Polygon(coords)  # Create a Shapely Polygon from the coordinate list\n","    # This builds a geometric object that can be used for spatial operations\n","\n","    props[\"geometry_wkt\"] = polygon.wkt  # Convert polygon to WKT format and store in props\n","    # Example: 'POLYGON ((-79.49 43.6, -79.48 43.6, -79.48 43.61, ...))'\n","\n","    rows.append(props)  # Add enriched props dictionary to the final list\n","\n","# Creating a PySpark dataframe to store enriched geometry\n","df = pd.DataFrame(rows)  # Convert to Pandas first\n","spark_df = spark.createDataFrame(df)  # Then to PySpark\n","\n","# Optional: Rename or cast columns\n","spark_df = spark_df.withColumnRenamed(\"AREA_SHORT_CODE\", \"ward_id\") \n","# Write to silver table with flattened properties and geometry for all features\n","spark_df.write.format(\"delta\") \\\n","    .mode(\"overwrite\") \\\n","    .option(\"mergeSchema\", \"true\") \\\n","    .saveAsTable(\"silver_03_dim_ward_topojson_toronto\")\n","\n","# Final Output as CSV\n","silver_df = spark.read.table(\"silver_03_dim_ward_topojson_toronto\")\n","silver_pdf = silver_df.toPandas()\n","silver_pdf.to_csv(\"/lakehouse/default/Files/silver_03_dim_ward_topojson_toronto.csv\", index=False)\n","\n","display(silver_pdf) # To get a download option as csv"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":72,"statement_ids":[67,68,69,70,71,72],"state":"finished","livy_statement_state":"available","session_id":"a6a548c1-05d3-4936-a258-927bbcb3ae53","normalized_state":"finished","queued_time":"2025-10-09T06:15:47.2697683Z","session_start_time":null,"execution_start_time":"2025-10-09T06:15:51.0806672Z","execution_finish_time":"2025-10-09T06:16:10.23355Z","parent_msg_id":"f2ecd0a7-6ad2-42d6-841e-ccb27df31c33"},"text/plain":"StatementMeta(, a6a548c1-05d3-4936-a258-927bbcb3ae53, 72, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: Shapely in /nfs4/pyenv-d46600b8-8d78-45d5-96a7-298be67dabe5/lib/python3.11/site-packages (2.1.2)\nRequirement already satisfied: numpy>=1.21 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from Shapely) (1.26.4)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\nWarning: PySpark kernel has been restarted to use updated packages.\n\n"]}],"execution_count":11,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8992b229-fec3-42ae-89f2-2dbdf05f933f"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"30fdebf4-ca3e-422a-8387-5f4d13fe2abf"}],"default_lakehouse":"30fdebf4-ca3e-422a-8387-5f4d13fe2abf","default_lakehouse_name":"lh_wards_toronto","default_lakehouse_workspace_id":"6a2d5314-0cf7-4016-a2f6-97ffae7192ad"}}},"nbformat":4,"nbformat_minor":5}